{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning III\n",
    "\n",
    "files needed = ('Hitters.csv')\n",
    "\n",
    "This book continues our foray into machine learning. Our goals here are modest. We would like to\n",
    "1. learn a bit about how machine learning is similar to, and different from, econometrics.  \n",
    "2. introduce the scikit-learn package which is chock full of 'machine learning' tools. \n",
    "3. work on some *validation* methods, which are an important part of the machine learning toolkit. \n",
    "4. explore the ridge and lasso regression models\n",
    "\n",
    "In this notebook, we study the ridge and lasso regressions. These are methods that put discipline on the importance of the independent variables of the regression.\n",
    "\n",
    "This notebook is loosely based on Chapter 6 from *An Introduction to Statistical Learning* by James, Witten, Hastie, and Tibshirani. This is an easy to follow introduction that is light on the mathematics behind the methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Econometrics v. Statistical learning\n",
    "This is overly broad and general, but hopefully helpful. Consider the model\n",
    "\n",
    "$$ y = f(X) + \\epsilon.$$\n",
    "\n",
    "### Econometrics\n",
    "Econometrics is mainly concerned with *inference*. By this, we mean that the goal is to understand the structure of $f(\\;)$. Econometricians are concerned about the 'true' value of the components of $f(\\;)$. We worry a lot about endogeneity, omitted variables, and whether the properties of $f(\\;)$ are consistent with the theory.  Practically, \n",
    "\n",
    "1. The $X$ variables included in the model are guided by theory.\n",
    "2. The focus is on in-sample fit. How well does the model fit the data?\n",
    "\n",
    "### Statistical (machine) learning\n",
    "Statistical learning is mainly concerned with *prediction*. By this, we mean the ability of the model to predict the values of $y$, given $X$, for data that are not used to estimate (or, in machine learning-ese, train) the model of $f(\\;)$. The guiding principle here is the *bias-variance tradeoff*. \\[more on this in a minute\\]. Practically, \n",
    "\n",
    "1. The $X$ variables included in the model are guided by the mean-variance tradeoff. \n",
    "2. The focus is on out-of-sample fit. How well does the model predict data not used to estimate the model?\n",
    "\n",
    "\\[The bias-variance tradeoff exist in econometrics, too. Theory typically disciplines our definition of $X$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model predictions\n",
    "\n",
    "The fundamental constraint in machine learning is the *bias-variance tradeoff*. Roughly speaking, there is no free lunch. \n",
    "\n",
    "Let's start with an example. Suppose we wanted to predict the number of people on the union terrace on a Friday. For 5 Fridays, we send out a team to count the number of people on the terrace (the $y$ variable). We also record the temperature, the price of beer, if it is a home football weekend, the value of the stock market, the number of sailboats on Mendota, and the euro-dollar exchange rate (the $X$ variables).  \n",
    "\n",
    "We use the data to estimate our model $y=f(X)+\\epsilon$ and use the $X$ data for a 6th Friday to predict the number of people on the terrace, $\\hat{y}$. We then evaluate our estimate by comparing our prediction to the actual number of people on the terrace on the 6th Friday, $(y - \\hat{y})^2$. This is a measure of how well our model works at predicting **out of sample**. \n",
    "\n",
    "Now, suppose we repeat this experiment $M$ times. We collect $M$ data sets, estimate the model $M$ times, predict the 6th Friday $M$ times. We can form the expected test mse as\n",
    "\n",
    "$$\\frac{1}{M}\\sum_{m=1}^M(y_m-\\hat{y}_m)^2$$\n",
    "\n",
    "It is straightforward to show that this expression can be decomposed into \n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{1}{M}\\sum_{m=1}^M(y_m-\\hat{y}_m)^2 & = \\left(E\\left[\\,\\hat{f}(X)\\right]-f(X) \\right)^2 + E\\,\\left(\\,\\hat{f}(X)-E\\left[\\,\\hat{f}(X)\\right]\\right)^2 + \\text{var}(\\epsilon)\\\\\n",
    "                                         &= \\text{bias}^2 + \\text{variance} + \\text{var}(\\epsilon).\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Note that all three terms are positive. We can't do anything about the third term, it is the *irreducible* error. The other two terms we would like to make as small as possible. Unfortunately, shrinking one of the two terms tends to increase the other term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias and variance\n",
    "The **bias term** tells us, on average, how close we get to the true model. Are we systematically over- or under-predicting $y$?\n",
    "\n",
    "The **variance term** tells us how much our estimates vary as we use different training datasets to estimate the model.\n",
    "\n",
    "Quick check: Think about shooting arrows at a target. What does a low-variance high-bias attempt look like? A low-bias low-variance look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The bias-variance tradeoff\n",
    "\n",
    "We would like to minimize the bias and the variance of the test mse. How can we do so? \n",
    "\n",
    "In the linear models we are considering, complexity increases as we add more variables to $X$. This includes adding polynomials of our independent variables, interactions, etc. How does complexity influence the testing error?  \n",
    "\n",
    "* As we **increase the complexity** of our model $f(\\;)$ the **squared bias tends to decrease**. \n",
    "\n",
    "* As we **increase the complexity** of our model $f(\\;)$ the **variance tends to increase**.\n",
    "\n",
    "This is the tradeoff. As we add features to the model, the bias decreases, but the variance increases. This gives rise to a u-shaped mse. This [figure](http://www-bcf.usc.edu/~gareth/ISL/Chapter2/2.12.pdf) from James et al. is a good illustration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "\n",
    "Behind the bias-variance tradoff is the idea of overfitting. The more complex the model, the more it will capture variation in $y$ due to the random error ($\\epsilon$). \n",
    "\n",
    "* This makes the model fit the data better (lower bias). We are capturing $y$ behavior from both $f(\\;)$ and $\\epsilon$.\n",
    "* This makes the model more variable. A new set of training data will have different $\\epsilon$'s. The estimate will change to match these new values of $\\epsilon$. Since $\\epsilon$ is not related to $f(\\;)$, we are making the estimate noisier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrinkage methods\n",
    "The bias-variance tradeoff says that we want to constrain our model's complexity. There are many, many, many ways to go about this. For linear models, two common and easy to grasp methods are the ridge and the lasso regression. \n",
    "\n",
    "Let's see how they work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # data handling\n",
    "import numpy as np                  # numerical methods\n",
    "import matplotlib.pyplot as plt     # plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data on baseball players. Each row is a player. The variable we would like to predict is salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 322 entries, 0 to 321\n",
      "Data columns (total 21 columns):\n",
      "Unnamed: 0    322 non-null object\n",
      "AtBat         322 non-null int64\n",
      "Hits          322 non-null int64\n",
      "HmRun         322 non-null int64\n",
      "Runs          322 non-null int64\n",
      "RBI           322 non-null int64\n",
      "Walks         322 non-null int64\n",
      "Years         322 non-null int64\n",
      "CAtBat        322 non-null int64\n",
      "CHits         322 non-null int64\n",
      "CHmRun        322 non-null int64\n",
      "CRuns         322 non-null int64\n",
      "CRBI          322 non-null int64\n",
      "CWalks        322 non-null int64\n",
      "League        322 non-null object\n",
      "Division      322 non-null object\n",
      "PutOuts       322 non-null int64\n",
      "Assists       322 non-null int64\n",
      "Errors        322 non-null int64\n",
      "Salary        263 non-null float64\n",
      "NewLeague     322 non-null object\n",
      "dtypes: float64(1), int64(16), object(4)\n",
      "memory usage: 52.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base = pd.read_csv('Hitters.csv')\n",
    "print(base.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>...</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Andy Allanson</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Alan Ashby</td>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>...</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  \\\n",
       "0  -Andy Allanson    293    66      1    30   29     14      1     293     66   \n",
       "1     -Alan Ashby    315    81      7    24   38     39     14    3449    835   \n",
       "\n",
       "     ...      CRuns  CRBI  CWalks  League Division PutOuts  Assists  Errors  \\\n",
       "0    ...         30    29      14       A        E     446       33      20   \n",
       "1    ...        321   414     375       N        W     632       43      10   \n",
       "\n",
       "   Salary  NewLeague  \n",
       "0     NaN          A  \n",
       "1   475.0          N  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data look okay, but we only have salary for 263 observations. Let's drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 263 entries, 1 to 321\n",
      "Data columns (total 21 columns):\n",
      "Unnamed: 0    263 non-null object\n",
      "AtBat         263 non-null int64\n",
      "Hits          263 non-null int64\n",
      "HmRun         263 non-null int64\n",
      "Runs          263 non-null int64\n",
      "RBI           263 non-null int64\n",
      "Walks         263 non-null int64\n",
      "Years         263 non-null int64\n",
      "CAtBat        263 non-null int64\n",
      "CHits         263 non-null int64\n",
      "CHmRun        263 non-null int64\n",
      "CRuns         263 non-null int64\n",
      "CRBI          263 non-null int64\n",
      "CWalks        263 non-null int64\n",
      "League        263 non-null object\n",
      "Division      263 non-null object\n",
      "PutOuts       263 non-null int64\n",
      "Assists       263 non-null int64\n",
      "Errors        263 non-null int64\n",
      "Salary        263 non-null float64\n",
      "NewLeague     263 non-null object\n",
      "dtypes: float64(1), int64(16), object(4)\n",
      "memory usage: 45.2+ KB\n"
     ]
    }
   ],
   "source": [
    "base = base.dropna()\n",
    "base.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS\n",
    "\n",
    "Let's start with ols to get a feel for things. Start by loading some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model                          # ols, ridge, lasso, \n",
    "from sklearn.preprocessing import StandardScaler          # normalize variables to have mu=0, std=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose some variables that are potentially useful for predicting salary. We are purposely making this set large. The goal is determine how to constrain our choices. \n",
    "\n",
    "The ridge regression works best if the $X$ variables are on the same scale. The `StandardScaler()` normalizes the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travis/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/travis/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "var_list = ['Hits', 'RBI', 'HmRun', 'Walks', 'Errors', 'Years', 'Assists', 'AtBat', 'Runs', 'CAtBat', 'CHits', 'CRuns', 'CWalks']\n",
    "\n",
    "# Standardize the X vars so they have mean = 0 and std = 1\n",
    "X = StandardScaler().fit_transform(base[var_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the OLS regression. Don't worry about the l2 norm stuff yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 342.86853172   56.76095882   31.72386749  150.31756567  -10.80513874\n",
      "  -28.76438817   25.9039893  -299.7189859   -95.89253928 -346.33866351\n",
      "  257.07761972  448.22175687 -157.44988341]\n",
      "The l2 norm of the ols coefficients is 810.4.\n"
     ]
    }
   ],
   "source": [
    "res_ols = linear_model.LinearRegression().fit(X, base['Salary'])\n",
    "coef_norm_ols = np.linalg.norm(res_ols.coef_, ord=2)\n",
    "\n",
    "print(res_ols.coef_)\n",
    "print('The l2 norm of the ols coefficients is {0:5.1f}.'.format(coef_norm_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ridge regression\n",
    "\n",
    "The ridge regression chooses $\\beta$ to minimize the residual sum of squares plus a penalty function \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "=& \\text{RSS}+ \\alpha \\left(\\sum_{j=1}^p \\beta_j^2\\right)^{0.5}\\\\\n",
    "=&\\sum_{i=1}^n(y_i-\\hat{y}_i)^2 + \\alpha \\left(\\sum_{j=1}^p \\beta_j^2\\right)^{0.5}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "OLS minimizes RSS, so if $\\alpha=0$ ridge collapses to OLS. We call $\\alpha$ the tuning parameter. When $\\alpha>0$, models are penalized for how large their coefficients are. The term multiplying $\\alpha$ is the l2 norm of the coefficient vector.  \n",
    "\n",
    "The `Ridge()` function is part of `linear_models` in scikit-learn [(docs)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's estimate the model with $\\alpha=0$. This should return the ols estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 342.86853172   56.76095882   31.72386749  150.31756567  -10.80513874\n",
      "  -28.76438817   25.9039893  -299.7189859   -95.89253928 -346.33866351\n",
      "  257.07761972  448.22175687 -157.44988341]\n",
      "The l2 norm of the ridge(a=0) coefficients is 810.4.\n"
     ]
    }
   ],
   "source": [
    "res_ridge_0 = linear_model.Ridge(alpha = 0.0).fit(X, base['Salary'])\n",
    "coef_norm_r0 = np.linalg.norm(res_ridge_0.coef_, ord=2)\n",
    "\n",
    "print(res_ridge_0.coef_)\n",
    "print('The l2 norm of the ridge(a=0) coefficients is {0:5.1f}.'.format(coef_norm_r0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now estimate the ridge model with $\\alpha=100$. This adds a penalty to each coefficient that is not zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 52.15138012  38.4847365    8.50483461  50.13721432 -11.04140017\n",
      "   5.05574661  -2.28073256   2.33576236  26.24338138  38.80799151\n",
      "  59.32436779  59.90473347  20.04176666]\n",
      "The l2 norm of the ridge(a=100) coefficients is 129.0.\n"
     ]
    }
   ],
   "source": [
    "res_ridge_100 = linear_model.Ridge(alpha = 100.0).fit(X, base['Salary'])\n",
    "coef_norm_r100 = np.linalg.norm(res_ridge_100.coef_, ord=2)\n",
    "\n",
    "print(res_ridge_100.coef_)\n",
    "print('The l2 norm of the ridge(a=100) coefficients is {0:5.1f}.'.format(coef_norm_r100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That decreased the norm of the coefficients quite a bit. We can keep going... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.26292247 22.88938261 14.84319012 25.27605131 -2.84991212 17.94244586\n",
      " -0.10430381 17.54807161 21.14484914 27.12005935 30.11332925 30.81759733\n",
      " 23.94825642]\n",
      "The l2 norm of the ridge(a=800) coefficients is  78.9.\n"
     ]
    }
   ],
   "source": [
    "res_ridge_800 = linear_model.Ridge(alpha = 800.0).fit(X, base['Salary'])\n",
    "coef_norm_r800 = np.linalg.norm(res_ridge_800.coef_, ord=2)\n",
    "\n",
    "print(res_ridge_800.coef_)\n",
    "print('The l2 norm of the ridge(a=800) coefficients is {0:5.1f}.'.format(coef_norm_r800))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>ols</th>\n",
       "      <th>ridge 100</th>\n",
       "      <th>ridge 800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hits</td>\n",
       "      <td>342.868532</td>\n",
       "      <td>52.151380</td>\n",
       "      <td>24.262922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBI</td>\n",
       "      <td>56.760959</td>\n",
       "      <td>38.484737</td>\n",
       "      <td>22.889383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>31.723867</td>\n",
       "      <td>8.504835</td>\n",
       "      <td>14.843190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walks</td>\n",
       "      <td>150.317566</td>\n",
       "      <td>50.137214</td>\n",
       "      <td>25.276051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-10.805139</td>\n",
       "      <td>-11.041400</td>\n",
       "      <td>-2.849912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Years</td>\n",
       "      <td>-28.764388</td>\n",
       "      <td>5.055747</td>\n",
       "      <td>17.942446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Assists</td>\n",
       "      <td>25.903989</td>\n",
       "      <td>-2.280733</td>\n",
       "      <td>-0.104304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-299.718986</td>\n",
       "      <td>2.335762</td>\n",
       "      <td>17.548072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Runs</td>\n",
       "      <td>-95.892539</td>\n",
       "      <td>26.243381</td>\n",
       "      <td>21.144849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>-346.338664</td>\n",
       "      <td>38.807992</td>\n",
       "      <td>27.120059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHits</td>\n",
       "      <td>257.077620</td>\n",
       "      <td>59.324368</td>\n",
       "      <td>30.113329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>448.221757</td>\n",
       "      <td>59.904733</td>\n",
       "      <td>30.817597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>-157.449883</td>\n",
       "      <td>20.041767</td>\n",
       "      <td>23.948256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        var         ols  ridge 100  ridge 800\n",
       "0      Hits  342.868532  52.151380  24.262922\n",
       "1       RBI   56.760959  38.484737  22.889383\n",
       "2     HmRun   31.723867   8.504835  14.843190\n",
       "3     Walks  150.317566  50.137214  25.276051\n",
       "4    Errors  -10.805139 -11.041400  -2.849912\n",
       "5     Years  -28.764388   5.055747  17.942446\n",
       "6   Assists   25.903989  -2.280733  -0.104304\n",
       "7     AtBat -299.718986   2.335762  17.548072\n",
       "8      Runs  -95.892539  26.243381  21.144849\n",
       "9    CAtBat -346.338664  38.807992  27.120059\n",
       "10    CHits  257.077620  59.324368  30.113329\n",
       "11    CRuns  448.221757  59.904733  30.817597\n",
       "12   CWalks -157.449883  20.041767  23.948256"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'var': var_list, \n",
    "              'ols': res_ols.coef_ , 'ridge 100':res_ridge_100.coef_, 'ridge 800':res_ridge_800.coef_ })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What size penalty? \n",
    "\n",
    "We see that increasing $\\alpha$ decreases the norm of the coefficients. How big should $\\alpha$ be? We want the $\\alpha$ that gives us the best test mse. As we discussed last week, cross-validation methods allow us to evaluate test mses.\n",
    "\n",
    "The scikit package has a method that combines the ridge estimation with cross validation. It is called `RidgeCV()` [(docs)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass to `RidgeCV()` a list of the alpha values to try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_grid = [1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4]\n",
    "\n",
    "# Setting 'store_cv_values' to true will hang on to all the test mses from the CV. Otherwise, it only keep the best one.\n",
    "model = linear_model.RidgeCV(alphas=alpha_grid, store_cv_values = True).fit(X,base['Salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns an object with useful attributes and methods. Let's look at a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha from the candidate alphas is 1.0.\n"
     ]
    }
   ],
   "source": [
    "# The .alpha_ holds the best alpha\n",
    "print('The best alpha from the candidate alphas is {0}.'.format(model.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        var        coef\n",
      "0      Hits  309.382723\n",
      "1       RBI   61.508414\n",
      "2     HmRun   21.763078\n",
      "3     Walks  140.610067\n",
      "4    Errors  -12.050349\n",
      "5     Years  -47.933631\n",
      "6   Assists   19.984472\n",
      "7     AtBat -277.165125\n",
      "8      Runs  -70.493630\n",
      "9    CAtBat -173.607372\n",
      "10    CHits  177.955937\n",
      "11    CRuns  355.839427\n",
      "12   CWalks -139.569671\n"
     ]
    }
   ],
   "source": [
    "best_coef_ridge = pd.DataFrame({'var':var_list, 'coef': model.coef_}) \n",
    "print(best_coef_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.02843609e+04 3.01781068e+04 2.91875911e+04 ... 2.44419200e+00\n",
      "  1.35781601e+03 3.14392936e+03]\n",
      " [4.90961822e+04 4.90869411e+04 4.89995087e+04 ... 1.81722250e+04\n",
      "  9.46378842e+03 4.23064769e+03]\n",
      " [3.58334242e+05 3.58009759e+05 3.54643288e+05 ... 1.34723883e+05\n",
      "  5.49162558e+04 6.19574577e+03]\n",
      " ...\n",
      " [3.57189181e+03 3.58819796e+03 3.73565465e+03 ... 1.18305515e+04\n",
      "  1.32823134e+04 2.04707709e+04]\n",
      " [8.11076387e+04 8.10128280e+04 8.01251664e+04 ... 4.62882943e+04\n",
      "  8.80650163e+04 1.58284001e+05]\n",
      " [2.87812484e+04 2.89069399e+04 3.01449649e+04 ... 4.67532198e+04\n",
      "  9.66306892e+04 1.87097272e+05]]\n",
      "(263, 7)\n"
     ]
    }
   ],
   "source": [
    "# Since I set 'store_cv_values' to true, I have the matrix of all the test mse. Columns correspond to alpha values, \n",
    "# and there is one row for each observation, since the function uses loocv\n",
    "\n",
    "print(model.cv_values_)\n",
    "print(model.cv_values_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([124401.99686713, 124327.02083352, 123702.9384668 , 121624.58267113,\n",
       "       125267.96774173, 136848.44181746, 184530.51723419])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean test mse for each value of alpha\n",
    "model.cv_values_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The lasso regression\n",
    "The lasso regression works like the ridge, but with a different penalty function. \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "=& \\text{RSS}+ \\alpha \\sum_{j=1}^p | \\beta_j|\\\\\n",
    "=&\\sum_{i=1}^n(y_i-\\hat{y}_i)^2 + \\alpha \\sum_{j=1}^p | \\beta_j|\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The penalty function here is the l1 norm, or the sum of the absolute values of the absolute values of the coefficient. The major difference between the ridge and the lasso is that the lasso can generate coefficients that are zero, dropping them from the model and making it simpler.\n",
    "\n",
    "The `Lasso` regression is part of `linear_models` in scikit-learn [(docs)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 342.89783759   56.76284806   31.72132886  150.32357815  -10.80369482\n",
      "  -28.78042787   25.90056085 -299.74466361  -95.90077659 -346.15890107\n",
      "  256.90508626  448.24973975 -157.47305179]\n",
      "The l2 norm of the lasso(a=0) coefficients is 2251.6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/travis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/travis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "res_lasso_0 = linear_model.Lasso(alpha = 0.0).fit(X, base['Salary'])\n",
    "coef_norm_l0 = np.linalg.norm(res_lasso_0.coef_, ord=1)\n",
    "\n",
    "print(res_lasso_0.coef_)\n",
    "print('The l2 norm of the lasso(a=0) coefficients is {0:5.1f}.'.format(coef_norm_l0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        var     lasso 2\n",
      "0      Hits  289.542400\n",
      "1       RBI   68.101418\n",
      "2     HmRun    2.138459\n",
      "3     Walks  123.811873\n",
      "4    Errors   -3.454889\n",
      "5     Years  -47.045848\n",
      "6   Assists    4.797088\n",
      "7     AtBat -260.218269\n",
      "8      Runs  -41.705288\n",
      "9    CAtBat   -0.000000\n",
      "10    CHits   10.262085\n",
      "11    CRuns  336.280067\n",
      "12   CWalks -123.029009\n",
      "\n",
      "The l1 norm of the lasso(a=2) coefficients is 1310.4.\n"
     ]
    }
   ],
   "source": [
    "res_lasso_2 = linear_model.Lasso(alpha = 2.0).fit(X, base['Salary'])\n",
    "coef_norm_2 = np.linalg.norm(res_lasso_2.coef_, ord=1)\n",
    "\n",
    "lassos = pd.DataFrame({'var':var_list, 'lasso 2': res_lasso_2.coef_}) \n",
    "print(lassos)\n",
    "print('\\nThe l1 norm of the lasso(a=2) coefficients is {0:5.1f}.'.format(coef_norm_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "Take a few minutes and try the following. Feel free to chat with those around if you get stuck. The TA and I are here, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Try estimating a lasso regression when $\\alpha = 5$. Compare the coefficient vector to the lasso with $\\alpha=2$ from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>lasso 2</th>\n",
       "      <th>lasso 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hits</td>\n",
       "      <td>289.542400</td>\n",
       "      <td>187.192908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBI</td>\n",
       "      <td>68.101418</td>\n",
       "      <td>53.895913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>2.138459</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walks</td>\n",
       "      <td>123.811873</td>\n",
       "      <td>84.479341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-3.454889</td>\n",
       "      <td>-4.387499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Years</td>\n",
       "      <td>-47.045848</td>\n",
       "      <td>-25.720740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Assists</td>\n",
       "      <td>4.797088</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-260.218269</td>\n",
       "      <td>-144.987736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Runs</td>\n",
       "      <td>-41.705288</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHits</td>\n",
       "      <td>10.262085</td>\n",
       "      <td>66.157744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>336.280067</td>\n",
       "      <td>180.220618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>-123.029009</td>\n",
       "      <td>-32.203122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        var     lasso 2     lasso 5\n",
       "0      Hits  289.542400  187.192908\n",
       "1       RBI   68.101418   53.895913\n",
       "2     HmRun    2.138459    0.000000\n",
       "3     Walks  123.811873   84.479341\n",
       "4    Errors   -3.454889   -4.387499\n",
       "5     Years  -47.045848  -25.720740\n",
       "6   Assists    4.797088   -0.000000\n",
       "7     AtBat -260.218269 -144.987736\n",
       "8      Runs  -41.705288   -0.000000\n",
       "9    CAtBat   -0.000000   -0.000000\n",
       "10    CHits   10.262085   66.157744\n",
       "11    CRuns  336.280067  180.220618\n",
       "12   CWalks -123.029009  -32.203122"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_lasso_5 = linear_model.Lasso(alpha = 5.0).fit(X, base['Salary'])\n",
    "coef_norm_5 = np.linalg.norm(res_lasso_5.coef_, ord=1)\n",
    "\n",
    "lassos = pd.DataFrame({'var':var_list, 'lasso 2':res_lasso_2.coef_, \"lasso 5\":res_lasso_5.coef_})\n",
    "lassos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Estimate lasso regressions with $\\alpha$ equal to 10 and 200. What is happening to the coefficients? What is happening to the norm of the coefficients? Does this make sense? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        var     lasso 2     lasso 5    lasso 10  lasso 200\n",
      "0      Hits  289.542400  187.192908   75.623355   0.000000\n",
      "1       RBI   68.101418   53.895913   39.965107   0.000000\n",
      "2     HmRun    2.138459    0.000000    0.000000   0.000000\n",
      "3     Walks  123.811873   84.479341   62.899989   0.000000\n",
      "4    Errors   -3.454889   -4.387499   -8.154722   0.000000\n",
      "5     Years  -47.045848  -25.720740   -0.000000   0.000000\n",
      "6   Assists    4.797088   -0.000000   -0.000000   0.000000\n",
      "7     AtBat -260.218269 -144.987736   -0.000000   0.000000\n",
      "8      Runs  -41.705288   -0.000000    0.000000   0.000000\n",
      "9    CAtBat   -0.000000   -0.000000    0.000000   0.000000\n",
      "10    CHits   10.262085   66.157744   56.927126   0.000000\n",
      "11    CRuns  336.280067  180.220618  135.248380  53.351392\n",
      "12   CWalks -123.029009  -32.203122   -0.000000   0.000000\n",
      "\n",
      "The norm of the lasso(a=2) coefficients is 1310.4\n",
      "\n",
      "The norm of the lasso(a=5) coefficients is 779.2\n",
      "\n",
      "The norm of the lasso(a=10) coefficients is 378.8\n",
      "\n",
      "The norm of the lasso(a=200) coefficients is 53.4\n"
     ]
    }
   ],
   "source": [
    "res_lasso_10 = linear_model.Lasso(alpha = 10.0).fit(X, base['Salary'])\n",
    "coef_norm_10 = np.linalg.norm(res_lasso_10.coef_, ord=1)\n",
    "\n",
    "res_lasso_200 = linear_model.Lasso(alpha = 200.0).fit(X, base['Salary'])\n",
    "coef_norm_200 = np.linalg.norm(res_lasso_200.coef_, ord=1)\n",
    "\n",
    "lassos = pd.DataFrame({'var':var_list, 'lasso 2':res_lasso_2.coef_, \"lasso 5\":res_lasso_5.coef_, \n",
    "                       \"lasso 10\":res_lasso_10.coef_, \"lasso 200\":res_lasso_200.coef_})\n",
    "print(lassos)\n",
    "a = [2, 5, 10, 200]\n",
    "coef_norm = [coef_norm_2, coef_norm_5, coef_norm_10, coef_norm_200]\n",
    "i = 0\n",
    "for var in a: \n",
    "    print(\"\\nThe norm of the lasso(a={})\".format(var), \"coefficients is {0:4.1f}\".format(coef_norm[i]))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the `LassoCV()` function [(docs)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV) to estimate lasso regressions for the following grid of alphas:\n",
    "```python\n",
    "alpha_grid = [1, 1.5, 2, 3, 4, 5, 6, 8, 10]\n",
    "```\n",
    "Set the `cv` parameter to 10. This means the method will use k-fold cross validation with k=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_grid = [1, 1.5, 2, 3, 4, 5, 6, 8, 10]\n",
    "\n",
    "LassoModel = linear_model.LassoCV(alphas=alpha_grid, cv=10).fit(X, base.Salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Which $\\alpha$ worked best? \n",
    "5. Use the `.mse_path_` attribute of the object returned by `LassoCV()` to return a (9,10) sized array. The 9 corresponds to the number of alphas and the 10 corresponds to the test mses from the 10-fold cross validation the function is using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha from the candidate alphas for Lasso regression is 2.0.\n",
      "[[ 59715.45367525  40325.34629318 248441.91775733 102133.40225221\n",
      "  135626.58114878  91300.43734036 290687.83887259 114133.23332923\n",
      "   75302.6025012  111842.68754428]\n",
      " [ 62267.10326526  40614.58420742 246838.92085146 100362.85290138\n",
      "  133602.83519904  90579.28724818 292537.70413761 118046.56171965\n",
      "   76584.49546511 111928.76197747]\n",
      " [ 67553.82290672  41537.28766873 240442.49097707  96252.73211127\n",
      "  131157.54015128  90802.56340968 289330.92141273 122781.23550956\n",
      "   81206.42903536 106662.7529034 ]\n",
      " [ 70495.39299391  41858.73905725 236679.13919188  92603.36939772\n",
      "  128543.52970488  91294.18805385 285868.64189977 125913.78872457\n",
      "   83177.63932055 101999.64271963]\n",
      " [ 73848.52629952  41151.75163075 230450.94620454  90531.23594616\n",
      "  126024.39306217  92180.97774063 282279.51051266 130457.8941669\n",
      "   84956.6190894   97712.14570727]\n",
      " [ 77864.94959285  40572.59262406 223585.51442406  89141.05713518\n",
      "  124045.91149555  93633.53989815 278629.4203275  135509.24181038\n",
      "   87496.85904708  93943.05276899]\n",
      " [ 82363.27852277  39040.88874203 217331.17261732  88294.3611948\n",
      "  122635.73230375  95001.97024334 275226.8483902  140981.00992522\n",
      "   90909.62133671  89747.2339065 ]\n",
      " [ 83772.81109736  38417.21709388 214169.56781793  88564.61175082\n",
      "  122544.92611894  95752.61354281 275805.36199734 144346.59793266\n",
      "   93796.8815303   87845.34945082]\n",
      " [ 84574.78642874  37773.42708953 210061.95397108  89489.47193079\n",
      "  123220.24273919  96538.0128406  276895.96901921 150193.34993902\n",
      "   97030.56304451  85911.12658242]]\n",
      "(9, 10)\n"
     ]
    }
   ],
   "source": [
    "print('The best alpha from the candidate alphas for Lasso regression is {0}.'.format(LassoModel.alpha_))\n",
    "\n",
    "print(LassoModel.mse_path_)\n",
    "\n",
    "print(LassoModel.mse_path_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a plot with $\\alpha$ on the x-axis and the average test mse on the y-axis. To make sure the mse correspond to the correct alpha, use the `.alphas_` attribute of the results object for the x values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(LassoModel.alphas_, LassoModel.mse_path_.mean(axis=1))\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_title(\"Average Test MSE for Different alphas\")\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"Average Test MSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Now let the computer sort out the best tuning parameter. Call `LassoCV()` as before, but do not use the 'alphas' argument. The algorithm will search for the best $\\alpha$.  \n",
    "\n",
    "What is the optimal $\\alpha$? \n",
    "\n",
    "What $\\alpha$'s did the algorithm try? \\[Use the `.alphas_` attribute.\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha from the candidate alphas for Lasso regression is 2.0550112515416843.\n",
      "The algorithm tried the following alphas:\n",
      " [2.53351392e+02 2.36276356e+02 2.20352121e+02 2.05501125e+02\n",
      " 1.91651037e+02 1.78734399e+02 1.66688298e+02 1.55454065e+02\n",
      " 1.44976981e+02 1.35206018e+02 1.26093585e+02 1.17595299e+02\n",
      " 1.09669770e+02 1.02278394e+02 9.53851728e+01 8.89565314e+01\n",
      " 8.29611589e+01 7.73698544e+01 7.21553852e+01 6.72923537e+01\n",
      " 6.27570743e+01 5.85274575e+01 5.45829028e+01 5.09041978e+01\n",
      " 4.74734253e+01 4.42738753e+01 4.12899643e+01 3.85071589e+01\n",
      " 3.59119052e+01 3.34915630e+01 3.12343438e+01 2.91292535e+01\n",
      " 2.71660393e+01 2.53351392e+01 2.36276356e+01 2.20352121e+01\n",
      " 2.05501125e+01 1.91651037e+01 1.78734399e+01 1.66688298e+01\n",
      " 1.55454065e+01 1.44976981e+01 1.35206018e+01 1.26093585e+01\n",
      " 1.17595299e+01 1.09669770e+01 1.02278394e+01 9.53851728e+00\n",
      " 8.89565314e+00 8.29611589e+00 7.73698544e+00 7.21553852e+00\n",
      " 6.72923537e+00 6.27570743e+00 5.85274575e+00 5.45829028e+00\n",
      " 5.09041978e+00 4.74734253e+00 4.42738753e+00 4.12899643e+00\n",
      " 3.85071589e+00 3.59119052e+00 3.34915630e+00 3.12343438e+00\n",
      " 2.91292535e+00 2.71660393e+00 2.53351392e+00 2.36276356e+00\n",
      " 2.20352121e+00 2.05501125e+00 1.91651037e+00 1.78734399e+00\n",
      " 1.66688298e+00 1.55454065e+00 1.44976981e+00 1.35206018e+00\n",
      " 1.26093585e+00 1.17595299e+00 1.09669770e+00 1.02278394e+00\n",
      " 9.53851728e-01 8.89565314e-01 8.29611589e-01 7.73698544e-01\n",
      " 7.21553852e-01 6.72923537e-01 6.27570743e-01 5.85274575e-01\n",
      " 5.45829028e-01 5.09041978e-01 4.74734253e-01 4.42738753e-01\n",
      " 4.12899643e-01 3.85071589e-01 3.59119052e-01 3.34915630e-01\n",
      " 3.12343438e-01 2.91292535e-01 2.71660393e-01 2.53351392e-01]\n"
     ]
    }
   ],
   "source": [
    "LassoModel_comp = linear_model.LassoCV(cv=10).fit(X, base.Salary)\n",
    "\n",
    "print('The best alpha from the candidate alphas for Lasso regression is {0}.'.format(LassoModel_comp.alpha_))\n",
    "\n",
    "print(\"The algorithm tried the following alphas:\\n\", LassoModel_comp.alphas_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Using the `mse_path_` and `alphas_` attributes, create a plot with $\\alpha$ on the x-axis and the average test mse on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(LassoModel_comp.alphas_, LassoModel_comp.mse_path_.mean(axis=1))\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_title(\"Average Test MSE for Different alphas, Searched by the Computer\")\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"Average Test MSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Display the optimal coefficient vector. Did the lasso eliminate any variables? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        var  lasso_coef\n",
      "0      Hits  286.786874\n",
      "1       RBI   68.325339\n",
      "2     HmRun    1.474243\n",
      "3     Walks  122.818539\n",
      "4    Errors   -3.312956\n",
      "5     Years  -46.653438\n",
      "6   Assists    4.403061\n",
      "7     AtBat -257.913655\n",
      "8      Runs  -39.978953\n",
      "9    CAtBat   -0.000000\n",
      "10    CHits   11.966717\n",
      "11    CRuns  332.473667\n",
      "12   CWalks -121.022429\n",
      "The Lasso regression eliminated variable 'CAtBat'\n"
     ]
    }
   ],
   "source": [
    "lasso_comp = pd.DataFrame({\"var\":var_list, \"lasso_coef\":LassoModel_comp.coef_})\n",
    "print(lasso_comp)\n",
    "\n",
    "print(\"The Lasso regression eliminated variable 'CAtBat'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
